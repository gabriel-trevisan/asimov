{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.llms import OpenAI\n",
    "\n",
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['pergunta'], input_types={}, partial_variables={}, template='\\n    Responda a seguinte pergunta do usuário: {pergunta}\\n')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template('''\n",
    "    Responda a seguinte pergunta do usuário: {pergunta}\n",
    "''')\n",
    "\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Responda a seguinte pergunta do usuário: O que é um buraco negro?\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.format(pergunta='O que é um buraco negro?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Composing prompts | Unindo múltiplos prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['lingua', 'n_palavras', 'pergunta'], input_types={}, partial_variables={}, template='\\n    Responda a pergunta em até: {n_palavras} palavras\\n\\n    Retorne a respota na {lingua}\\nResponda a pergunta seguinte seguindo as intruções: {pergunta}')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template_word_count = PromptTemplate.from_template('''\n",
    "    Responda a pergunta em até: {n_palavras} palavras\n",
    "''')\n",
    "\n",
    "template_lingua = PromptTemplate.from_template('''\n",
    "    Retorne a respota na {lingua}\n",
    "''')\n",
    "\n",
    "template_final = (\n",
    "    template_word_count\n",
    "    + template_lingua\n",
    "    + 'Responda a pergunta seguinte seguindo as intruções: {pergunta}'\n",
    ")\n",
    "\n",
    "template_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = template_final.format(n_palavras=10, lingua='inglês', pergunta='O que é uma estrela?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A star is a luminous celestial body made of gas.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Templates para Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Essa é minha dúvida: Quem sou eu?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_template('Essa é minha dúvida: {duvida}')\n",
    "chat_template.format_messages(duvida='Quem sou eu?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['nome_assistente', 'pergunta'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['nome_assistente'], input_types={}, partial_variables={}, template='Você é um assistente engraçado e se chama {nome_assistente}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Olá, como vai?'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Melhor agora! Como posso ajuda-lo?'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['pergunta'], input_types={}, partial_variables={}, template='{pergunta}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', 'Você é um assistente engraçado e se chama {nome_assistente}'),\n",
    "        ('human', 'Olá, como vai?'),\n",
    "        ('ai', 'Melhor agora! Como posso ajuda-lo?'),\n",
    "        ('human', '{pergunta}')\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'System: Você é um assistente engraçado e se chama Asimo\\nHuman: Olá, como vai?\\nAI: Melhor agora! Como posso ajuda-lo?\\nHuman: Qual o seu nome?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template.format(nome_assistente='Asimo', pergunta='Qual o seu nome?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='AI: Meu nome é Asimo, o assistente engraçado! Como posso fazer você rir hoje?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 53, 'total_tokens': 79, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-83316708-ed70-47ca-aa0e-4a1498792c88-0', usage_metadata={'input_tokens': 53, 'output_tokens': 26, 'total_tokens': 79, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "chat.invoke(chat_template.format(nome_assistente='Asimo', pergunta='Qual o seu nome?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Templates de Few-shot prompting para llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplos = [\n",
    "    {\"pergunta\": \"Quem viveu mais tempo, Muhammad Ali ou Alan Turing?\", \n",
    "     \"resposta\": \n",
    "     \"\"\"São necessárias perguntas de acompanhamento aqui: Sim. \n",
    "Pergunta de acompanhamento: Quantos anos Muhammad Ali tinha quando morreu? \n",
    "Resposta intermediária: Muhammad Ali tinha 74 anos quando morreu. \n",
    "Pergunta de acompanhamento: Quantos anos Alan Turing tinha quando morreu? \n",
    "Resposta intermediária: Alan Turing tinha 41 anos quando morreu. \n",
    "Então a resposta final é: Muhammad Ali \n",
    "\"\"\", \n",
    "    }, \n",
    "    {\"pergunta\": \"Quando nasceu o fundador do craigslist?\", \n",
    "     \"resposta\": \n",
    "\"\"\"São necessárias perguntas de acompanhamento aqui: Sim. \n",
    "Pergunta de acompanhamento: Quem foi o fundador do craigslist? \n",
    "Resposta intermediária: O craigslist foi fundado por Craig Newmark. \n",
    "Pergunta de acompanhamento: Quando nasceu Craig Newmark? \n",
    "Resposta intermediária: Craig Newmark nasceu em 6 de dezembro de 1952. \n",
    "Então a resposta final é: 6 de dezembro de 1952 \n",
    "\"\"\", \n",
    "    }, \n",
    "    {\"pergunta\": \"Quem foi o avô materno de George Washington?\",\n",
    "     \"resposta\": \n",
    "\"\"\"São necessárias perguntas de acompanhamento aqui: Sim. \n",
    "Pergunta de acompanhamento: Quem foi a mãe de George Washington? \n",
    "Resposta intermediária: A mãe de George Washington foi Mary Ball Washington. \n",
    "Pergunta de acompanhamento: Quem foi o pai de Mary Ball Washington? \n",
    "Resposta intermediária: O pai de Mary Ball Washington foi Joseph Ball. \n",
    "Então a resposta final é: Joseph Ball \n",
    "\"\"\", \n",
    "    },\n",
    "    {\"pergunta\": \"Os diretores de Jaws e Casino Royale são do mesmo país?\", \n",
    "     \"resposta\": \n",
    "\"\"\"São necessárias perguntas de acompanhamento aqui: Sim. \n",
    "Pergunta de acompanhamento: Quem é o diretor de Jaws? \n",
    "Resposta Intermediária: O diretor de Jaws é Steven Spielberg. \n",
    "Pergunta de acompanhamento: De onde é Steven Spielberg? \n",
    "Resposta Intermediária: Estados Unidos. \n",
    "Pergunta de acompanhamento: Quem é o diretor de Casino Royale? \n",
    "Resposta Intermediária: O diretor de Casino Royale é Martin Campbell. \n",
    "Pergunta de acompanhamento: De onde é Martin Campbell? \n",
    "Resposta Intermediária: Nova Zelândia. \n",
    "Então a resposta final é: Não \n",
    "\"\"\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pergunta Quem viveu mais tempo, Muhammad Ali ou Alan Turing?\\nSão necessárias perguntas de acompanhamento aqui: Sim. \\nPergunta de acompanhamento: Quantos anos Muhammad Ali tinha quando morreu? \\nResposta intermediária: Muhammad Ali tinha 74 anos quando morreu. \\nPergunta de acompanhamento: Quantos anos Alan Turing tinha quando morreu? \\nResposta intermediária: Alan Turing tinha 41 anos quando morreu. \\nEntão a resposta final é: Muhammad Ali \\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=['pergunta', 'resposta'],\n",
    "    template='Pergunta {pergunta}\\n{resposta}'\n",
    ")\n",
    "\n",
    "example_prompt.format(**exemplos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    examples=exemplos,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix='Pergunta: {input}',\n",
    "    input_variables=['input']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pergunta Quem viveu mais tempo, Muhammad Ali ou Alan Turing?\n",
      "São necessárias perguntas de acompanhamento aqui: Sim. \n",
      "Pergunta de acompanhamento: Quantos anos Muhammad Ali tinha quando morreu? \n",
      "Resposta intermediária: Muhammad Ali tinha 74 anos quando morreu. \n",
      "Pergunta de acompanhamento: Quantos anos Alan Turing tinha quando morreu? \n",
      "Resposta intermediária: Alan Turing tinha 41 anos quando morreu. \n",
      "Então a resposta final é: Muhammad Ali \n",
      "\n",
      "\n",
      "Pergunta Quando nasceu o fundador do craigslist?\n",
      "São necessárias perguntas de acompanhamento aqui: Sim. \n",
      "Pergunta de acompanhamento: Quem foi o fundador do craigslist? \n",
      "Resposta intermediária: O craigslist foi fundado por Craig Newmark. \n",
      "Pergunta de acompanhamento: Quando nasceu Craig Newmark? \n",
      "Resposta intermediária: Craig Newmark nasceu em 6 de dezembro de 1952. \n",
      "Então a resposta final é: 6 de dezembro de 1952 \n",
      "\n",
      "\n",
      "Pergunta Quem foi o avô materno de George Washington?\n",
      "São necessárias perguntas de acompanhamento aqui: Sim. \n",
      "Pergunta de acompanhamento: Quem foi a mãe de George Washington? \n",
      "Resposta intermediária: A mãe de George Washington foi Mary Ball Washington. \n",
      "Pergunta de acompanhamento: Quem foi o pai de Mary Ball Washington? \n",
      "Resposta intermediária: O pai de Mary Ball Washington foi Joseph Ball. \n",
      "Então a resposta final é: Joseph Ball \n",
      "\n",
      "\n",
      "Pergunta Os diretores de Jaws e Casino Royale são do mesmo país?\n",
      "São necessárias perguntas de acompanhamento aqui: Sim. \n",
      "Pergunta de acompanhamento: Quem é o diretor de Jaws? \n",
      "Resposta Intermediária: O diretor de Jaws é Steven Spielberg. \n",
      "Pergunta de acompanhamento: De onde é Steven Spielberg? \n",
      "Resposta Intermediária: Estados Unidos. \n",
      "Pergunta de acompanhamento: Quem é o diretor de Casino Royale? \n",
      "Resposta Intermediária: O diretor de Casino Royale é Martin Campbell. \n",
      "Pergunta de acompanhamento: De onde é Martin Campbell? \n",
      "Resposta Intermediária: Nova Zelândia. \n",
      "Então a resposta final é: Não \n",
      "\n",
      "\n",
      "Pergunta: Quem fez mais gols, Romário ou Pelé?\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(input='Quem fez mais gols, Romário ou Pelé?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSão necessárias perguntas de acompanhamento aqui: Sim. \\nPergunta de acompanhamento: Quantos gols Romário fez em sua carreira? \\nResposta intermediária: Romário fez um total de 772 gols em sua carreira. \\nPergunta de acompanhamento: Quantos gols Pelé fez em sua carreira? \\nResposta intermediária: Pelé fez um total de 1281 gols em sua carreira. \\nEntão a resposta final é: Pelé'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(prompt.format(input='Quem fez mais gols, Romário ou Pelé?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Templates de Few-shot prompting para chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Quem viveu mais tempo, Muhammad Ali ou Alan Turing?', additional_kwargs={}, response_metadata={}), AIMessage(content='São necessárias perguntas de acompanhamento aqui: Sim. \\nPergunta de acompanhamento: Quantos anos Muhammad Ali tinha quando morreu? \\nResposta intermediária: Muhammad Ali tinha 74 anos quando morreu. \\nPergunta de acompanhamento: Quantos anos Alan Turing tinha quando morreu? \\nResposta intermediária: Alan Turing tinha 41 anos quando morreu. \\nEntão a resposta final é: Muhammad Ali \\n', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('human', '{pergunta}'),\n",
    "    ('ai', '{resposta}')\n",
    "])\n",
    "\n",
    "print(example_prompt.format_messages(**exemplos[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_template = FewShotChatMessagePromptTemplate(\n",
    "    examples=exemplos,\n",
    "    example_prompt = example_prompt\n",
    ")\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    few_shot_template,\n",
    "    ('human', '{input}')\n",
    "])\n",
    "\n",
    "prompt = prompt_template.format_messages(input='Quem fez mais gols, Romário ou Pelé?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Pelé fez mais gols em sua carreira do que Romário. Pelé marcou mais de 1200 gols em sua carreira, enquanto Romário marcou cerca de 740 gols. Portanto, Pelé fez mais gols do que Romário.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 538, 'total_tokens': 597, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-9fe0d36a-bd18-45a6-bde8-da3eaa2b2790-0', usage_metadata={'input_tokens': 538, 'output_tokens': 59, 'total_tokens': 597, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
